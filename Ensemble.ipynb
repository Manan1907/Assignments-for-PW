{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, BaggingRegressor, RandomForestRegressor\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n"
      ],
      "metadata": {
        "id": "mJXuPP4iRk-E"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkvrsLRoGpnP",
        "outputId": "54eccd3b-facb-41bd-a568-65f1d354972f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.94\n",
            "\n",
            "Top 5 Most Important Features:\n",
            "worst perimeter         0.128273\n",
            "worst concave points    0.125543\n",
            "worst area              0.109792\n",
            "worst radius            0.103148\n",
            "mean concave points     0.084547\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Question 6: Write a Python program to:\n",
        "● Load the Breast Cancer dataset using sklearn.datasets.load_breast_cancer()\n",
        "● Train a Random Forest Classifier\n",
        "● Print the top 5 most important features based on feature importance scores.\n",
        "'''\n",
        "\n",
        "sklearn.datasets.load_breast_cancer()\n",
        "data = sklearn.datasets.load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
        "\n",
        "# Initialize and train the Random Forest Classifier\n",
        "# n_estimators: Number of trees in the forest\n",
        "# random_state: For reproducibility\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=1)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\\n\")\n",
        "\n",
        "# Get feature importances from the trained model\n",
        "feature_importances = rf_classifier.feature_importances_\n",
        "\n",
        "# Create a Pandas Series for better handling of feature names and importances\n",
        "feature_importance_series = pd.Series(feature_importances, index=X.columns)\n",
        "\n",
        "# Sort the features by importance in descending order\n",
        "sorted_feature_importances = feature_importance_series.sort_values(ascending=False)\n",
        "\n",
        "# Print the top 5 most important features\n",
        "print(\"Top 5 Most Important Features:\")\n",
        "print(sorted_feature_importances.head(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Question 7: Write a Python program to:\n",
        "● Train a Bagging Classifier using Decision Trees on the Iris dataset\n",
        "● Evaluate its accuracy and compare with a single Decision Tree.\n",
        "'''\n",
        "\n",
        "# Load the Iris dataset\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# 1. Train and evaluate a single Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=1)\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "dt_predictions = dt_classifier.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
        "print(f\"Accuracy of single Decision Tree: {dt_accuracy:.4f}\")\n",
        "\n",
        "# 2. Train and evaluate a Bagging Classifier with Decision Trees\n",
        "# n_estimators: number of base estimators (Decision Trees) in the ensemble\n",
        "# estimator: the base estimator to use (DecisionTreeClassifier in this case)\n",
        "bagging_classifier = BaggingClassifier(estimator=DecisionTreeClassifier(random_state=1),\n",
        "                                       n_estimators=10, random_state=1)\n",
        "bagging_classifier.fit(X_train, y_train)\n",
        "bagging_predictions = bagging_classifier.predict(X_test)\n",
        "bagging_accuracy = accuracy_score(y_test, bagging_predictions)\n",
        "print(f\"Accuracy of Bagging Classifier: {bagging_accuracy:.4f}\")\n",
        "\n",
        "# Compare the accuracies\n",
        "if bagging_accuracy > dt_accuracy:\n",
        "    print(\"\\nBagging Classifier performed better than the single Decision Tree.\")\n",
        "elif dt_accuracy > bagging_accuracy:\n",
        "    print(\"\\nSingle Decision Tree performed better than the Bagging Classifier.\")\n",
        "else:\n",
        "    print(\"\\nBoth models achieved the same accuracy.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efavtWXiRmyK",
        "outputId": "3c5c85b8-8982-4d6e-da82-eff8ca41fa54"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of single Decision Tree: 0.9667\n",
            "Accuracy of Bagging Classifier: 0.9667\n",
            "\n",
            "Both models achieved the same accuracy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Question 8: Write a Python program to:\n",
        "● Train a Random Forest Classifier\n",
        "● Tune hyperparameters max_depth and n_estimators using GridSearchCV\n",
        "● Print the best parameters and final accuracy\n",
        "'''\n",
        "\n",
        "# loading tips data for working\n",
        "df = sns.load_dataset('tips')\n",
        "\n",
        "X = df.drop('time', axis=1)\n",
        "y = df['time']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=1)\n",
        "\n",
        "\n",
        "\n",
        "cat_cols = [\"sex\", \"smoker\", \"day\"]\n",
        "num_cols = [\"total_bill\", \"tip\", \"size\"]\n",
        "\n",
        "num_pipeline = Pipeline(steps = [('imputation', SimpleImputer(strategy = \"median\")),\n",
        "                                ('scaling', StandardScaler())])\n",
        "cat_pipeline = Pipeline(steps = [('imputation', SimpleImputer(strategy = \"most_frequent\")),\n",
        "                                ('encoding', OneHotEncoder())])\n",
        "\n",
        "preprocessor = ColumnTransformer([(\"num_pipeline\", num_pipeline, num_cols),\n",
        "                  (\"cat_pipeline\", cat_pipeline, cat_cols)])\n",
        "\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 5, 10, 20],\n",
        "    'min_samples_leaf': [5, 10, 20,],\n",
        "    'n_estimators': [10, 25, 50, 100, 200]\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(rf, param_grid, cv=5)\n",
        "gs.fit(X_train, y_train)\n",
        "\n",
        "print(\"The best parameter are: \")\n",
        "print(gs.best_params_)\n",
        "print(f\"\\nThe accuracy score is: {gs.best_score_:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv_G7jrjRmj9",
        "outputId": "5cdd7d12-b1b9-4d47-c901-bcb62bb6837b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best parameter are: \n",
            "{'max_depth': 2, 'min_samples_leaf': 5, 'n_estimators': 10}\n",
            "\n",
            "The accuracy score is: 0.9795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Question 9: Write a Python program to:\n",
        "● Train a Bagging Regressor and a Random Forest Regressor on the California Housing dataset\n",
        "● Compare their Mean Squared Errors (MSE)\n",
        "'''\n",
        "\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "# Load the California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data\n",
        "y = housing.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Bagging Regressor\n",
        "bagging_regressor = BaggingRegressor(random_state=42)\n",
        "bagging_regressor.fit(X_train, y_train)\n",
        "y_pred_bagging = bagging_regressor.predict(X_test)\n",
        "mse_bagging = mean_squared_error(y_test, y_pred_bagging)\n",
        "\n",
        "# Train a Random Forest Regressor\n",
        "random_forest_regressor = RandomForestRegressor(random_state=42)\n",
        "random_forest_regressor.fit(X_train, y_train)\n",
        "y_pred_rf = random_forest_regressor.predict(X_test)\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "\n",
        "# Compare Mean Squared Errors\n",
        "print(f\"Mean Squared Error (Bagging Regressor): {mse_bagging:.3f}\")\n",
        "print(f\"\\nMean Squared Error (Random Forest Regressor): {mse_rf:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7abTcgVPRmQE",
        "outputId": "f5f0fbcc-4cce-4fdd-9139-16f5216a07a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (Bagging Regressor): 0.282\n",
            "\n",
            "Mean Squared Error (Random Forest Regressor): 0.255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Question 10: You are working as a data scientist at a financial institution to predict loan default.\n",
        "You have access to customer demographic and transaction history data. You decide to use ensemble techniques to increase model performance.\n",
        "Explain your step-by-step approach to:\n",
        "● Choose between Bagging or Boosting\n",
        "● Handle overfitting\n",
        "● Select base models\n",
        "● Evaluate performance using cross-validation\n",
        "● Justify how ensemble learning improves decision-making in this real-world context.\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "id": "acQN7MjZRmDE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}